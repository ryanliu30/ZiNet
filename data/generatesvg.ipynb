{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8d215d64",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydiffvg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [191]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m minidom\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbezier\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpydiffvg\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpkl\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydiffvg'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from fontTools import ttLib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn\n",
    "from shape import from_svg_path\n",
    "from xml.dom import minidom\n",
    "import bezier\n",
    "import pydiffvg\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef1efd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NotoSansCJKtc-Regular.otf',\n",
       " 'fontA.ttf',\n",
       " 'AdobeSongStd-Light.otf',\n",
       " 'AdobeFangsongStd-Regular.otf',\n",
       " 'AdobeHeitiStd-Regular.otf',\n",
       " 'AdobeKaitiStd-Regular.otf']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FONTDIR = \"fonts/\"\n",
    "PATHS = [path[len(FONTDIR):] for path in glob.glob(f'{FONTDIR}/*')] # list of font names\n",
    "SVG_OUTPUT_PATH = \"./SVGs\"      # svg output directory\n",
    "BEZIER_OUTPUT_PATH = \"./Bezier\" # Bezier output dir\n",
    "PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5459b473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Cleaning ./SVGs\n",
      "Finished Reconstructing Folders\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree(f'{SVG_OUTPUT_PATH}') #cleans OUTPUT_PATH and also removes it; will be added back in on the next for loop\n",
    "print(f'Finished Cleaning {SVG_OUTPUT_PATH}')\n",
    "for path in PATHS:  \n",
    "    #ensure every font has a corresponding folder, name of folder is just font file name\n",
    "    newpath = f'{SVG_OUTPUT_PATH}/{path}'\n",
    "    try:\n",
    "        os.makedirs(newpath)\n",
    "    except:\n",
    "        continue\n",
    "print(\"Finished Reconstructing Folders\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3837a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts = [ttLib.TTFont(FONTDIR + path) for path in PATHS]\n",
    "chars = pd.read_csv(\"./edu_standard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9f2d520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11151it [00:00, 685455.48it/s]\n",
      "11151it [00:01, 9554.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Generation for font NotoSansCJKtc-Regular.otf: ΔT = 14.379251956939697s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11151it [00:00, 1653726.18it/s]\n",
      "6322it [00:00, 10231.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Generation for font fontA.ttf: ΔT = 10.93431305885315s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11151it [00:00, 1607737.24it/s]\n",
      "11151it [00:00, 18879.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Generation for font AdobeSongStd-Light.otf: ΔT = 11.339351892471313s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11151it [00:00, 1641306.99it/s]\n",
      "11151it [00:00, 16966.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Generation for font AdobeFangsongStd-Regular.otf: ΔT = 10.832360029220581s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11151it [00:00, 1629527.00it/s]\n",
      "11151it [00:00, 16962.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Generation for font AdobeHeitiStd-Regular.otf: ΔT = 10.811652660369873s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11151it [00:00, 1651273.97it/s]\n",
      "11151it [00:00, 17546.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Generation for font AdobeKaitiStd-Regular.otf: ΔT = 11.516471147537231s\n",
      "Saved Font Support Matrix to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "supports = np.zeros((len(PATHS), len(chars[\"Character\"])))                # HasFound[i][j]: If the ith font supports character j\n",
    "# indexes mentioned in the code are all the index that they appear in the edu_standard.csv file.\n",
    "for i, font in enumerate(fonts): \n",
    "    for cmap in font['cmap'].tables:\n",
    "        if cmap.isUnicode():\n",
    "            st = time.time()\n",
    "            toGenerate = []  # List of characters supported by the font\n",
    "            indexes    = []  # The indexes of the characters in the above\n",
    "            for idx, char_ in enumerate(chars[\"Character\"]):\n",
    "                char = ord(char_)\n",
    "                if char in cmap.cmap:\n",
    "                    toGenerate.append(cmap.cmap[char]) # cmap.cmap[char] stores the CID for the given character\n",
    "                    indexes.append(idx)\n",
    "                supports[i, idx] = (char in cmap.cmap) \n",
    "\n",
    "            # Generate desired svg files\n",
    "            os.system(f'fonts2svg -c 000000 {FONTDIR}{PATHS[i]} -o {SVG_OUTPUT_PATH}/{PATHS[i]} -g {\",\".join(toGenerate)} > /dev/null') \n",
    "\n",
    "            for idx, svgName in zip(indexes, toGenerate):\n",
    "                os.rename(f'{SVG_OUTPUT_PATH}/{PATHS[i]}/{svgName}.svg', f'{SVG_OUTPUT_PATH}/{PATHS[i]}/{idx}.svg') # rename according to index\n",
    "            ed = time.time()\n",
    "            print(f'Finished Generation for font {PATHS[i]}: ΔT = {ed - st}s')\n",
    "            break\n",
    "            \n",
    "with open(\"./font_support.npy\", \"wb\") as f:\n",
    "    np.save(f, supports)\n",
    "    print(\"Saved Font Support Matrix to disk\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d151b4f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pickle' has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./font_support.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mpkl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m(HasFound, f)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved Font Support Matrix to disk\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pickle' has no attribute 'save'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6e4a5ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getBeziers(svg_path, cut_parts = 8):\n",
    "    \"\"\"\n",
    "    Takes an SVG file, and adds 8* anchor points to it, while elevating all curves into cubic ones. \n",
    "    output: a list of diffvg Paths. \n",
    "    \n",
    "    @param svg_path:  the path to the svg file to be cut\n",
    "    @param cut_parts: the factor of anchor points to add\n",
    "    \n",
    "    @return res:      a list of diffvg paths to be used in ML models\n",
    "    \"\"\"\n",
    "    mydoc = minidom.parse(svg_path)\n",
    "    path_tag = mydoc.getElementsByTagName(\"path\")\n",
    "    d_string = path_tag[0].attributes['d'].value\n",
    "    x = from_svg_path(d_string) \n",
    "    #y = pydiffvg.svg_to_scene(path_tag)\n",
    "    #print(y)\n",
    "    for curve in x:\n",
    "        paths = []\n",
    "        points = curve.points.clone()\n",
    "        num_control_points = curve.num_control_points.clone()\n",
    "        points = torch.cat([points, points[0].unsqueeze(0)], dim = 0) # push element 0 to last point\n",
    "        anchors = np.cumsum(num_control_points.clone() + 1) \n",
    "        anchors = torch.cat([torch.tensor([0]), anchors], dim = 0)\n",
    "        # anchors[i] and anchors[i + 1] are indices of anchors, anything in between are control points\n",
    "        for idx in range(len(anchors) - 1):\n",
    "            bezierCurve = bezier.Curve(points[anchors[idx] : anchors[idx + 1] + 1, :].T, degree = anchors[idx + 1] - anchors[idx])\n",
    "            while bezierCurve.degree < 3: # Make sure everything is cubic\n",
    "                bezierCurve = bezierCurve.elevate()\n",
    "            # Split curve into cut_parts parts \n",
    "            parts = []\n",
    "            for i in range(cut_parts):\n",
    "                parts.append(bezierCurve.specialize(i / 8, (i + 1) / 8))\n",
    "            paths = np.concatenate([paths, parts], axis = 0)\n",
    "        \n",
    "        newpoints = np.empty((0, 2))\n",
    "        new_controls = np.empty(0)\n",
    "        \n",
    "        for path in paths: # get paths back into diffsvg format\n",
    "            newpoints = np.concatenate([newpoints, path.nodes.T[ : -1, :]], axis = 0)\n",
    "            new_controls = np.concatenate([new_controls, [path.degree - 1]])\n",
    "        \n",
    "        curve.points = torch.tensor(newpoints)\n",
    "        curve.num_control_points = torch.tensor(new_controls)\n",
    "    \n",
    "    return x\n",
    " \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a2019644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584\n",
      "tensor([ 922., -301.], dtype=torch.float64)\n",
      "torch.Size([528])\n",
      "96\n",
      "tensor([ 707., -575.], dtype=torch.float64)\n",
      "torch.Size([32])\n",
      "96\n",
      "tensor([ 484., -480.], dtype=torch.float64)\n",
      "torch.Size([32])\n",
      "96\n",
      "tensor([ 714., -370.], dtype=torch.float64)\n",
      "torch.Size([32])\n",
      "96\n",
      "tensor([ 703., -268.], dtype=torch.float64)\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "seaborn.set()\n",
    "x = getBeziers(\"./SVGs/AdobeFangsongStd-Regular.otf/47.svg\")\n",
    "\n",
    "for curve in x:\n",
    "    print(len(curve.points))\n",
    "    print(curve.points[0])\n",
    "    print(curve.num_control_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a69e87ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphFromBezier(svg_path):\n",
    "    \"\"\"\n",
    "    @param svg_path      : the path of the svg file\n",
    "    \n",
    "    @return node_feature : Node feature matrix of shape [num_nodes, in_channels]\n",
    "    @return edge_index   : Graph connectivity matrix of shape [2, num_edges]\n",
    "    \n",
    "    return values are all numpy arrays and should be turned into Tensors later\n",
    "    \"\"\"\n",
    "    mydoc = minidom.parse(svg_path)\n",
    "    path_tag = mydoc.getElementsByTagName(\"path\")\n",
    "    d_string = path_tag[0].attributes['d'].value\n",
    "    x = from_svg_path(d_string) \n",
    "    \"\"\" debug mode: comment out\n",
    "    for curve in x:\n",
    "        for dim in curve.num_control_points:\n",
    "            assert(dim == 2)\n",
    "    \"\"\"\n",
    "    num_nodes = 0\n",
    "    indices = []\n",
    "    for curve in x:\n",
    "        indices.append(np.arange(num_nodes, num_nodes + len(curve.points)))\n",
    "        num_nodes += len(curve.points)\n",
    "        \n",
    "    node_feature = np.zeros((num_nodes, 3)) # position, is anchor\n",
    "    edge_index = [] #will have to transpose \n",
    "    \n",
    "    for i, curve in enumerate(x):\n",
    "        for j, point in enumerate(curve.points):\n",
    "            feat = np.zeros(3) # list of length 3\n",
    "            feat[ 0 : 2 ] = point\n",
    "            feat[2] = 1 if j % 3 == 0 else 0 #assumes that all paths are closed cubic paths!!\n",
    "            node_feature[indices[i][j]] = feat\n",
    "            \n",
    "            if(j % 3 == 0):\n",
    "                edge_index.append(np.array((indices[i][j], indices[i][(j + 3) % len(curve.points)])))\n",
    "            edge_index.append(np.array((indices[i][j], indices[i][(j + 1) % len(curve.points)])))\n",
    "            \n",
    "    return node_feature, np.array(edge_index).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b724d2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 922., -301.,    1.],\n",
       "        [ 881., -334.,    0.],\n",
       "        [ 864., -326.,    0.],\n",
       "        [ 821., -315.,    1.],\n",
       "        [ 749., -306.,    0.],\n",
       "        [ 754., -345.,    0.],\n",
       "        [ 757., -371.,    1.],\n",
       "        [ 767., -385.,    0.],\n",
       "        [ 780., -391.,    0.],\n",
       "        [ 785., -393.,    1.],\n",
       "        [ 785., -397.,    0.],\n",
       "        [ 780., -403.,    0.],\n",
       "        [ 742., -445.,    1.],\n",
       "        [ 713., -405.,    0.],\n",
       "        [ 524., -384.,    0.],\n",
       "        [ 524., -451.,    1.],\n",
       "        [ 752., -476.,    0.],\n",
       "        [ 763., -477.,    0.],\n",
       "        [ 764., -479.,    1.],\n",
       "        [ 757., -488.,    0.],\n",
       "        [ 736., -513.,    0.],\n",
       "        [ 744., -557.,    1.],\n",
       "        [ 746., -569.,    0.],\n",
       "        [ 751., -576.,    0.],\n",
       "        [ 767., -585.,    1.],\n",
       "        [ 774., -589.,    0.],\n",
       "        [ 773., -593.,    0.],\n",
       "        [ 768., -599.,    1.],\n",
       "        [ 732., -639.,    0.],\n",
       "        [ 702., -606.,    0.],\n",
       "        [ 524., -589.,    1.],\n",
       "        [ 524., -659.,    0.],\n",
       "        [ 882., -693.,    0.],\n",
       "        [ 896., -694.,    1.],\n",
       "        [ 896., -698.,    0.],\n",
       "        [ 886., -706.,    0.],\n",
       "        [ 840., -740.,    1.],\n",
       "        [ 807., -726.,    0.],\n",
       "        [ 697., -708.,    0.],\n",
       "        [ 524., -691.,    1.],\n",
       "        [ 525., -757.,    0.],\n",
       "        [ 528., -772.,    0.],\n",
       "        [ 542., -792.,    1.],\n",
       "        [ 548., -800.,    0.],\n",
       "        [ 547., -805.,    0.],\n",
       "        [ 539., -811.,    1.],\n",
       "        [ 465., -864.,    0.],\n",
       "        [ 457., -853.,    0.],\n",
       "        [ 477., -821.,    1.],\n",
       "        [ 483., -779.,    0.],\n",
       "        [ 484., -688.,    0.],\n",
       "        [ 107., -654.,    1.],\n",
       "        [ 158., -610.,    0.],\n",
       "        [ 198., -622.,    0.],\n",
       "        [ 269., -633.,    1.],\n",
       "        [ 484., -654.,    0.],\n",
       "        [ 484., -585.,    0.],\n",
       "        [ 313., -568.,    1.],\n",
       "        [ 282., -617.,    0.],\n",
       "        [ 272., -612.,    0.],\n",
       "        [ 278., -591.,    1.],\n",
       "        [ 281., -571.,    0.],\n",
       "        [ 282., -545.,    0.],\n",
       "        [ 285., -483.,    1.],\n",
       "        [ 286., -464.,    0.],\n",
       "        [ 285., -455.,    0.],\n",
       "        [ 277., -442.,    1.],\n",
       "        [ 307., -392.,    0.],\n",
       "        [ 313., -382.,    0.],\n",
       "        [ 323., -385.,    1.],\n",
       "        [ 323., -430.,    0.],\n",
       "        [ 484., -447.,    0.],\n",
       "        [ 484., -380.,    1.],\n",
       "        [ 199., -349.,    0.],\n",
       "        [ 249., -314.,    0.],\n",
       "        [ 278., -323.,    1.],\n",
       "        [ 331., -330.,    0.],\n",
       "        [ 484., -346.,    0.],\n",
       "        [ 484., -279.,    1.],\n",
       "        [  67., -240.,    0.],\n",
       "        [ 123., -198.,    0.],\n",
       "        [ 166., -211.,    1.],\n",
       "        [ 282., -229.,    0.],\n",
       "        [ 484., -247.,    0.],\n",
       "        [ 484., -174.,    1.],\n",
       "        [ 204., -144.,    0.],\n",
       "        [ 252., -108.,    0.],\n",
       "        [ 280., -117.,    1.],\n",
       "        [ 346., -127.,    0.],\n",
       "        [ 484., -140.,    0.],\n",
       "        [ 484.,   -9.,    1.],\n",
       "        [ 482.,   10.,    0.],\n",
       "        [ 473.,   25.,    0.],\n",
       "        [ 354.,  -37.,    1.],\n",
       "        [ 346.,  -24.,    0.],\n",
       "        [ 410.,   26.,    0.],\n",
       "        [ 454.,   65.,    1.],\n",
       "        [ 485.,   99.,    0.],\n",
       "        [ 494.,  109.,    0.],\n",
       "        [ 498.,  109.,    1.],\n",
       "        [ 503.,   98.,    0.],\n",
       "        [ 519.,   67.,    0.],\n",
       "        [ 524.,   38.,    1.],\n",
       "        [ 524.,  -30.,    0.],\n",
       "        [ 524., -143.,    0.],\n",
       "        [ 767., -165.,    1.],\n",
       "        [ 781., -166.,    0.],\n",
       "        [ 781., -168.,    0.],\n",
       "        [ 772., -177.,    1.],\n",
       "        [ 737., -212.,    0.],\n",
       "        [ 745., -271.,    0.],\n",
       "        [ 919., -287.,    1.],\n",
       "        [ 934., -288.,    0.],\n",
       "        [ 935., -291.,    0.],\n",
       "        [ 707., -575.,    1.],\n",
       "        [ 698., -503.,    0.],\n",
       "        [ 524., -484.,    0.],\n",
       "        [ 524., -555.,    1.],\n",
       "        [ 484., -480.,    1.],\n",
       "        [ 322., -463.,    0.],\n",
       "        [ 319., -534.,    0.],\n",
       "        [ 484., -551.,    1.],\n",
       "        [ 714., -370.,    1.],\n",
       "        [ 706., -301.,    0.],\n",
       "        [ 524., -283.,    0.],\n",
       "        [ 524., -350.,    1.],\n",
       "        [ 703., -268.,    1.],\n",
       "        [ 694., -196.,    0.],\n",
       "        [ 524., -178.,    0.],\n",
       "        [ 524., -251.,    1.]]),\n",
       " array([[  0,   0,   1,   2,   3,   3,   4,   5,   6,   6,   7,   8,   9,\n",
       "           9,  10,  11,  12,  12,  13,  14,  15,  15,  16,  17,  18,  18,\n",
       "          19,  20,  21,  21,  22,  23,  24,  24,  25,  26,  27,  27,  28,\n",
       "          29,  30,  30,  31,  32,  33,  33,  34,  35,  36,  36,  37,  38,\n",
       "          39,  39,  40,  41,  42,  42,  43,  44,  45,  45,  46,  47,  48,\n",
       "          48,  49,  50,  51,  51,  52,  53,  54,  54,  55,  56,  57,  57,\n",
       "          58,  59,  60,  60,  61,  62,  63,  63,  64,  65,  66,  66,  67,\n",
       "          68,  69,  69,  70,  71,  72,  72,  73,  74,  75,  75,  76,  77,\n",
       "          78,  78,  79,  80,  81,  81,  82,  83,  84,  84,  85,  86,  87,\n",
       "          87,  88,  89,  90,  90,  91,  92,  93,  93,  94,  95,  96,  96,\n",
       "          97,  98,  99,  99, 100, 101, 102, 102, 103, 104, 105, 105, 106,\n",
       "         107, 108, 108, 109, 110, 111, 111, 112, 113, 114, 114, 115, 116,\n",
       "         117, 117, 118, 118, 119, 120, 121, 121, 122, 122, 123, 124, 125,\n",
       "         125, 126, 126, 127, 128, 129, 129],\n",
       "        [  3,   1,   2,   3,   6,   4,   5,   6,   9,   7,   8,   9,  12,\n",
       "          10,  11,  12,  15,  13,  14,  15,  18,  16,  17,  18,  21,  19,\n",
       "          20,  21,  24,  22,  23,  24,  27,  25,  26,  27,  30,  28,  29,\n",
       "          30,  33,  31,  32,  33,  36,  34,  35,  36,  39,  37,  38,  39,\n",
       "          42,  40,  41,  42,  45,  43,  44,  45,  48,  46,  47,  48,  51,\n",
       "          49,  50,  51,  54,  52,  53,  54,  57,  55,  56,  57,  60,  58,\n",
       "          59,  60,  63,  61,  62,  63,  66,  64,  65,  66,  69,  67,  68,\n",
       "          69,  72,  70,  71,  72,  75,  73,  74,  75,  78,  76,  77,  78,\n",
       "          81,  79,  80,  81,  84,  82,  83,  84,  87,  85,  86,  87,  90,\n",
       "          88,  89,  90,  93,  91,  92,  93,  96,  94,  95,  96,  99,  97,\n",
       "          98,  99, 102, 100, 101, 102, 105, 103, 104, 105, 108, 106, 107,\n",
       "         108, 111, 109, 110, 111,   0, 112, 113,   0, 117, 115, 116, 117,\n",
       "         116, 114, 121, 119, 120, 121, 120, 118, 125, 123, 124, 125, 124,\n",
       "         122, 129, 127, 128, 129, 128, 126]]))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphFromBezier(\"./SVGs/AdobeFangsongStd-Regular.otf/47.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d803a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
